# CS181-P4 - Reinforcement learning with Swingy Monkey

This repository documents the work completed by Matthew Stewart, Claire Stolz, and Shane Ong for the final practical of CS181: Machine Learning, involving the application of reinforcement learning to the flappy bird-style game 'Swingy Monkey'.

In this documentation we outline the methods used to attain the highest possible score on the game by using Q-learning and its deep learning-based extensions, commonly referred to as DQN (Deep Q-Learning) and DDQN (Double Deep Q-Learning).

<p align="center">
  <img width="700" height="500" src="https://github.com/mrdragonbear/CS181-P4/blob/master/Swingy_Monkey.png">
</p>



# Overview of Models

The score for the three models developed in this practical are outlined in the table below.
  
Model | Score
:------------: | :-------------:
Q-Learning | 100
DQN | 100
DDQN | 100

Hyperparameter optimization was performed in order to optimize for the &epsilon-greedy policy, the learning rate &alpha, as well as the discount rate &gamma, and other factors such as the neural architecture and hyperparameters of the deep neural network in the deep learning models.
